{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from scripts.preprocess_data import preprocess_data\n",
    "from utils.helpers import list_from_yaml\n",
    "from utils.metrics import confusion_matrix, classifcation_metrics\n",
    "from utils.serialization import load_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('./data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing movie data\n",
      "Finding unique genres\n",
      "Only keepnig genres that appear at least 200 times in 42202 movies\n",
      "----------\n",
      "Statistics\n",
      "----------\n",
      "42202 movies\n",
      "Number of unique genres: 91\n",
      "Word count per plot summary - min: 1, mean: 309.42, std: 317.49, median: 186.00, 90% : 738, 95% : 909, 99% : 1376, max: 4922\n",
      "Genre count per movie - min: 0, mean: 3.35, std: 2.05, median: 3,  max: 15\n",
      "----------\n",
      "-- Saving --\n",
      "Saving movie data as csv as : prepared_movie_data.csv\n",
      "Saving unique genre to index mapping as: genre_mapping.json\n",
      "Saving genre_mapping.json to: data\n",
      "Saving movie plots as: plot_summaries.json\n",
      "Saving plot_summaries.json to: data\n",
      "----------\n",
      "-- Saved --\n"
     ]
    }
   ],
   "source": [
    "preprocess_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_name</th>\n",
       "      <th>plot_summary</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>Set in the second half of the 22nd century the...</td>\n",
       "      <td>['Thriller', 'Adventure', 'Horror', 'Supernatu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>White Of The Eye</td>\n",
       "      <td>A series of murders of rich young women throug...</td>\n",
       "      <td>['Psychological thriller', 'Thriller']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Woman in Flames</td>\n",
       "      <td>Eva an upper class housewife becomes frustrate...</td>\n",
       "      <td>['Drama']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Sorcerer's Apprentice</td>\n",
       "      <td>Every hundred years the evil Morgana returns t...</td>\n",
       "      <td>['World cinema', 'Fantasy', 'Family Film', 'Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Little city</td>\n",
       "      <td>Adam a San Francisco-based artist who works as...</td>\n",
       "      <td>['Romantic comedy', 'Comedy-drama', 'Comedy', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  movie_name  \\\n",
       "0             Ghosts of Mars   \n",
       "1           White Of The Eye   \n",
       "2          A Woman in Flames   \n",
       "3  The Sorcerer's Apprentice   \n",
       "4                Little city   \n",
       "\n",
       "                                        plot_summary  \\\n",
       "0  Set in the second half of the 22nd century the...   \n",
       "1  A series of murders of rich young women throug...   \n",
       "2  Eva an upper class housewife becomes frustrate...   \n",
       "3  Every hundred years the evil Morgana returns t...   \n",
       "4  Adam a San Francisco-based artist who works as...   \n",
       "\n",
       "                                              genres  \n",
       "0  ['Thriller', 'Adventure', 'Horror', 'Supernatu...  \n",
       "1             ['Psychological thriller', 'Thriller']  \n",
       "2                                          ['Drama']  \n",
       "3  ['World cinema', 'Fantasy', 'Family Film', 'Ad...  \n",
       "4  ['Romantic comedy', 'Comedy-drama', 'Comedy', ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_data = pd.read_csv(DATA_PATH / 'prepared_movie_data.csv')\n",
    "movie_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lower & Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to lower case\n",
    "movie_data.loc[:, 'plot_summary'] = movie_data['plot_summary'].apply(lambda x: x.lower())\n",
    "# tokenizing\n",
    "movie_data.loc[:, 'tokenized_summary'] = movie_data['plot_summary'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add 100 most frequent words to list of stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add stop words\n",
    "frequent_words = defaultdict(lambda: 0)\n",
    "for summary in movie_data['tokenized_summary']:\n",
    "    for word in summary:\n",
    "        frequent_words[word] += 1\n",
    "frequent_words = sorted(frequent_words.items(), key=lambda item: item[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0       1\n",
      "0     the  822296\n",
      "1      to  479962\n",
      "2     and  455497\n",
      "3       a  375882\n",
      "4      of  260660\n",
      "..    ...     ...\n",
      "95  tries   12035\n",
      "96   help   12016\n",
      "97      s   11738\n",
      "98    n't   11717\n",
      "99    now   11690\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "most_frequent_words = pd.DataFrame(frequent_words).head(100)\n",
    "print(most_frequent_words)\n",
    "most_frequent_words = set(most_frequent_words[0]).union(set(stopwords.words('English')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove stopwords from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "def remove_stopwords(x, stopwords=most_frequent_words, stemmer=stemmer):\n",
    "    return ' '.join([stemmer.stem(word) for word in x if word not in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data.loc[:, 'cleaned_plot_summary'] = movie_data['tokenized_summary'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert genres to multilabel one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded file: genre_mapping.json successfully\n"
     ]
    }
   ],
   "source": [
    "genre_mapping = load_json(DATA_PATH, 'genre_mapping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genre_index(x, mapping=genre_mapping):\n",
    "    x = list_from_yaml(x)\n",
    "    return [genre_mapping[genre] for genre in x]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data.loc[:, 'genre_indices'] = movie_data['genres'].apply(get_genre_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = mlb.fit_transform(movie_data['genre_indices'].to_numpy())\n",
    "X = tfidf.fit_transform(movie_data['cleaned_plot_summary'].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SPLIT = 0.8\n",
    "VALIDATION_SPLIT = 0.5\n",
    "RANDOM_STATE = 42 # seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data has 33761 movies, validation data has 4220 movies, test data has 4221 movies,\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X, y, train_size=TRAIN_SPLIT, shuffle=True,\n",
    "                                         random_state=RANDOM_STATE)\n",
    "val_X, test_X, val_y, test_y = train_test_split(test_X, test_y, train_size=VALIDATION_SPLIT, shuffle=True,\n",
    "                                         random_state=RANDOM_STATE)\n",
    "print(f'train data has {train_X.shape[0]} movies,'\n",
    "      f' validation data has {val_X.shape[0]} movies,'\n",
    "      f' test data has {test_X.shape[0]} movies,')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovr = OneVsRestClassifier(LogisticRegression(solver='sag'))\n",
    "\n",
    "pred_y = ovr.fit(train_X, train_y).predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.7085714285714285,\n",
       " 'recall': 0.18957609451007645,\n",
       " 'accuracy': 0.966717953924777,\n",
       " 'f1': 0.29912280701754385}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP, TN, FP, FN = confusion_matrix(pred_y, test_y)\n",
    "test_metrics = classifcation_metrics(TP, TN, FP, FN)\n",
    "test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovr = OneVsRestClassifier(LinearSVC())\n",
    "\n",
    "pred_y = ovr.fit(train_X, train_y).predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.6297309621523027,\n",
       " 'recall': 0.2879082696316887,\n",
       " 'accuracy': 0.9669808987506215,\n",
       " 'f1': 0.39515475225332636}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP, TN, FP, FN = confusion_matrix(pred_y, test_y)\n",
    "test_metrics = classifcation_metrics(TP, TN, FP, FN)\n",
    "test_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
